{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.loadProcessed as loadp\n",
    "\n",
    "counts = loadp.load_processed_count()\n",
    "locations = loadp.load_processed_locations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7426b6fc",
   "metadata": {},
   "source": [
    "# Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f06f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes\n",
    "import matplotlib.dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fff889",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_sensor: pd.DataFrame = counts.groupby(counts['sensing_date'])['daily_count'].sum().reset_index()\n",
    "\n",
    "ax: matplotlib.axes.Axes = counts_by_sensor.plot.line(\n",
    "    x='sensing_date', y='daily_count',\n",
    ")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9f45b",
   "metadata": {},
   "source": [
    "I wanted to visualise how the number of counts changes over time. \n",
    "As we can see in the above plot, there is a general trend upwards. There are a few reasons for this I will need to explore. First of these is that more sensors are installed over time so we need to account for that, this will most likely involve treating sensors as categorical variables. Secondly, since I am most interested in the behaviour of the population, rather than the congestion of the city, I would like to account for the population size of melbourne as well as that has increased significantly over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_sensor: pd.DataFrame = (\n",
    "    counts.groupby(\n",
    "        ['sensor_id', 'sensing_date'], observed=True\n",
    "    )['daily_count']                                                   # ['daily_count'] makes it a series with the multiindex as the index\n",
    "    .sum()                                                  # So the sum just sums over the values (aggregates hourly_count per sensor x time combo)\n",
    "    .unstack(level='sensor_id')                                        # Seperates out the multiindex to treat each sensor as a level, date makes up the new index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3715eaba",
   "metadata": {},
   "source": [
    "To make the initial analysis a bit easier, I'm going to focus on a single key sensor. Later in the process I'll reintroduce other sensors so that I can improve the power of my tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sensor_loc = locations[locations['sensor_name'] == 'UM1_T']\n",
    "\n",
    "single_sensor_counts = pd.DataFrame.merge(\n",
    "    single_sensor_loc, counts, how='inner', on='sensor_id'\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(single_sensor_counts['sensing_date'], single_sensor_counts['daily_count'], label='Daily Counts')\n",
    "\n",
    "highlight_day, highlight_month = 1, 3 \n",
    "for year in range(\n",
    "    single_sensor_counts['sensing_date'].min().year,\n",
    "    single_sensor_counts['sensing_date'].max().year + 1\n",
    "):\n",
    "    nye = pd.Timestamp(year=year, month=highlight_month, day=highlight_day)\n",
    "    x_coord = float(matplotlib.dates.date2num(nye))\n",
    "\n",
    "    ax.axvline(x_coord, color='red', linestyle='--')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax.set_title(f'{single_sensor_loc['sensor_description'].item()} Count highlighting 1st March (~start of sem 1)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31bf36f",
   "metadata": {},
   "source": [
    "I found that many sensor locations have a specific pattern of activity that aligns with events in that location. Pictured is near The University of Melbourne where we can see a clear correlation with the university semesters. We can see that there is a sharp peak at the start of semester, which slowly decreases as it gets later in semester. \n",
    "\n",
    "In other locations I saw other such yearly patters such as for the Australian Open finals, new years eve, or pre-christmas shopping.\n",
    "\n",
    "I believe that many of these location specific variations will be ironed out later such that we can see the effect of covid on foot traffic.\n",
    "We can see that the foot traffic was much lower during lockdowns in 2020 and 2021 and then does not quite recover afterwards, which is supporting my theory. However with the specific example above, this may be due to a change in university policy to allow for more online learning.\n",
    "\n",
    "I found that the Spencer St-Collins St (North) sensor seemed to have a fairly stable pattern with few gaps in data so I will begin my analysis with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102bd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sensor_loc = locations[locations['sensor_name'] == 'Col620_T']\n",
    "\n",
    "single_sensor_counts = pd.DataFrame.merge(\n",
    "    single_sensor_loc[['sensor_id']], counts, how='inner', on='sensor_id'\n",
    ").drop(columns=['sensor_id'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(single_sensor_counts['sensing_date'], single_sensor_counts['daily_count'], label='Daily Counts')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax.set_title(f'{single_sensor_loc['sensor_description'].item()} counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac854df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config as config\n",
    "\n",
    "# Taking timeslice from a year before first lockdown to year after last lockdown\n",
    "counts_in_timeslice = (\n",
    "    single_sensor_counts[\n",
    "        (single_sensor_counts['sensing_date'] > (config.FIRST_LOCKDOWN_START - pd.Timedelta(days=365)))\n",
    "        & (single_sensor_counts['sensing_date'] < (config.LAST_LOCKDOWN_END + pd.Timedelta(days=365)))\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(counts_in_timeslice['sensing_date'], counts_in_timeslice['daily_count'], label='Daily Counts')\n",
    "\n",
    "for start, end in config.LOCKDOWN_DATES.itertuples(index=False):\n",
    "    ax.axvspan(\n",
    "        start, end,\n",
    "        color='red',\n",
    "        alpha=0.3\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax.set_title('Pedestrian Counts at Spencer St-Collins St (North) with covid stage 3 lockdowns shaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_2019 = (\n",
    "    single_sensor_counts[\n",
    "        single_sensor_counts['sensing_date'].dt.year == 2019\n",
    "    ]\n",
    ")\n",
    "\n",
    "counts_2025 = (\n",
    "    single_sensor_counts[\n",
    "        single_sensor_counts['sensing_date'].dt.year == 2025\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(counts_2019['sensing_date'].dt.dayofyear, counts_2019['daily_count'], label='2019', color='red')\n",
    "ax.plot(counts_2025['sensing_date'].dt.dayofyear, counts_2025['daily_count'], label='2025', color='blue')\n",
    "\n",
    "ax.set_xlabel('Day of Year')\n",
    "ax.set_ylabel('Pedestrian Counts')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10103f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "sensor_averages = counts_by_sensor.mean()\n",
    "fig, (ax_1, ax_2) = plt.subplots(2)\n",
    "ax_1.hist(sensor_averages, 10)\n",
    "ax_1.set_xlabel('Mean daily count per sensor')\n",
    "ax_1.set_ylabel('Number of Sensors')\n",
    "\n",
    "log_sensor_averages = sensor_averages.apply(lambda x: math.log(x))\n",
    "ax_2.hist(log_sensor_averages, 10)\n",
    "ax_2.set_xlabel('Log of Mean daily count per sensor')\n",
    "ax_2.set_ylabel('Number of Sensors')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "print(f'log(X) has mean {log_sensor_averages.mean().item()} and variance {log_sensor_averages.var().item()}\\n    with kurtosis {log_sensor_averages.kurtosis().item()} and skew {log_sensor_averages.skew().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "fig = sm.qqplot(log_sensor_averages, line='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a3d28",
   "metadata": {},
   "source": [
    "Plotting the daily sensor count (over the entirety of each sensor's readings rather than just 2019 and 2025) we can see that it follows an exponential trend with a significant right-skew. Taking the log of this, we see quite a convincing normal distribution, if a bit flat with a negative kurtosis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738afbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_counts = pd.merge(\n",
    "    counts.query('daily_count == 0'), locations,\n",
    "    how=\"inner\", on='sensor_id'\n",
    ")\n",
    "zero_counts = (\n",
    "    zero_counts[\n",
    "        (zero_counts['sensing_date'].dt.year == 2019) | (zero_counts['sensing_date'].dt.year == 2025)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting RMIT building 80\n",
    "single_sensor_loc = locations[locations['sensor_name'] == 'RMIT_T']\n",
    "\n",
    "single_sensor_counts = pd.DataFrame.merge(\n",
    "    single_sensor_loc[['sensor_id']], counts, how='inner', on='sensor_id'\n",
    ").drop(columns=['sensor_id'])\n",
    "ax.plot(single_sensor_counts['sensing_date'], single_sensor_counts['daily_count'], label='Daily Counts')\n",
    "\n",
    "# Plotting RMIT building 14\n",
    "single_sensor_loc = locations[locations['sensor_name'] == 'WatCit_T']\n",
    "\n",
    "single_sensor_counts = pd.DataFrame.merge(\n",
    "    single_sensor_loc[['sensor_id']], counts, how='inner', on='sensor_id'\n",
    ").drop(columns=['sensor_id'])\n",
    "ax.plot(single_sensor_counts['sensing_date'], single_sensor_counts['daily_count'], label='Daily Counts')\n",
    "\n",
    "# Set up axis\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax.set_title(f'RMIT building 14 vs 80 counts')\n",
    "ax.set_xticks(ax.get_xticks()[::2])\n",
    "\n",
    "ax.axhline(color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b891d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf = counts[counts['sensing_date'].dt.year == 2025]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
