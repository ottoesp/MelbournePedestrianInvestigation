{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd700607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T09:48:53.907518300Z",
     "start_time": "2026-01-15T09:48:53.893520300Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cec119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T09:48:53.946336800Z",
     "start_time": "2026-01-15T09:48:53.910574100Z"
    }
   },
   "outputs": [],
   "source": [
    "import src.loadProcessed as loadp\n",
    "\n",
    "counts: pd.DataFrame = loadp.load_processed_count()\n",
    "locations: pd.DataFrame = loadp.load_processed_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93788c77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T09:48:53.980006200Z",
     "start_time": "2026-01-15T09:48:53.950391500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take the intersection of those sets\n",
    "common_sensors = (\n",
    "    set(counts[counts['sensing_date'].dt.year == 2019]['sensor_id'].unique()) \n",
    "    & set(counts[counts['sensing_date'].dt.year == 2025]['sensor_id'].unique())\n",
    ")\n",
    "\n",
    "# Filter to only those sensors\n",
    "counts_with_common_dates = counts[counts['sensor_id'].isin(common_sensors)]\n",
    "\n",
    "# Limit to only 2019 and 2025 with non-zero values\n",
    "data: pd.DataFrame = (\n",
    "    counts_with_common_dates[\n",
    "        counts_with_common_dates['sensing_date'].dt.year.isin([2019, 2025])\n",
    "    ].query('daily_count > 0')\n",
    ")\n",
    "data['year'] = data['sensing_date'].dt.year.astype('category')\n",
    "# data.drop(columns=['sensing_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd15606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T09:48:53.989927100Z",
     "start_time": "2026-01-15T09:48:53.981014100Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy.highlevel as phl\n",
    "import math\n",
    "\n",
    "# We want to log transform since counts have a power relation\n",
    "log_data = data.copy()\n",
    "log_data['daily_count'] = log_data['daily_count'].apply(math.log)\n",
    "\n",
    "model = smf.mixedlm(\n",
    "    'daily_count ~ year + day',     # Defines the response and fixed effects\n",
    "    log_data,                       \n",
    "    groups=log_data['sensor_id'],   # Defines how to cluster the data\n",
    "    re_formula='~ year'             # Random effect that differs across the clusters\n",
    ")\n",
    "result = model.fit(reml=False)\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22084312",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = smf.mixedlm(\n",
    "    'daily_count ~ day*year',     # Defines the response and fixed effects\n",
    "    log_data,                       \n",
    "    groups=log_data['sensor_id'],  # Defines how to cluster the data\n",
    "    re_formula='~ year'            # Random effect that differs across the clusters\n",
    ")\n",
    "result_2 = model_2.fit(reml=False)\n",
    "\n",
    "print(result_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfdf118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.aic, result_2.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3bfdb",
   "metadata": {},
   "source": [
    "The interactive model has a significantly lower AIC so it should be preffered, since days are roughly equally represented I can reconstruct the average yearly effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d347ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fixed_year = result_2.params['year[T.2025]']\n",
    "log_fixed_intercept = result_2.params['Intercept']\n",
    "\n",
    "log_sensor_effects = pd.DataFrame.from_dict(\n",
    "    result_2.random_effects,\n",
    "    orient='index'\n",
    ").rename(\n",
    "    columns={\n",
    "        'year[T.2025]': 'friday_year_effect',\n",
    "        'Group' : 'intercept_deviation'\n",
    "    }\n",
    ")\n",
    "\n",
    "for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Saturday', 'Sunday']:\n",
    "    day_param = f'day[T.{day}]:year[T.2025]'\n",
    "    if day_param in result_2.params:\n",
    "        # Add fixed main effect + day√óyear effect + sensor random effect\n",
    "        log_sensor_effects[f'{day.lower()}_year_effect'] = (\n",
    "            log_fixed_year + result_2.params[day_param] + log_sensor_effects['friday_year_effect']\n",
    "        )\n",
    "\n",
    "log_sensor_effects['geometric_mean_pedestrians_2019'] = log_sensor_effects['intercept_deviation'] + log_fixed_intercept\n",
    "\n",
    "# Since each day of the week has roughly the same number of counts, we can just take the mean of the day specific effects\n",
    "log_sensor_effects['mean_year_effect'] = log_sensor_effects[[\n",
    "    'monday_year_effect', 'tuesday_year_effect', 'wednesday_year_effect',\n",
    "    'thursday_year_effect', 'friday_year_effect', 'saturday_year_effect', 'sunday_year_effect'\n",
    "]].mean(axis=1)\n",
    "\n",
    "log_sensor_effects = log_sensor_effects.drop(columns=['intercept_deviation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fixed_intercept = np.exp(log_fixed_intercept)\n",
    "fixed_year_effect = np.exp(log_fixed_year)\n",
    "\n",
    "convexivity_correction = np.exp(result_2.scale / 2)\n",
    "\n",
    "sensor_effects: pd.DataFrame = log_sensor_effects.apply(np.exp)\n",
    "sensor_effects['arithmetic_mean_pedestrians_2019'] = sensor_effects['geometric_mean_pedestrians_2019'] * convexivity_correction\n",
    " \n",
    "for index, series in sensor_effects.sample(20).iterrows(): \n",
    "    ax.axline((0, series['arithmetic_mean_pedestrians_2019']), (1, series['arithmetic_mean_pedestrians_2019']*series['mean_year_effect']))\n",
    "\n",
    "ax.axline(\n",
    "    (0, fixed_intercept * convexivity_correction),\n",
    "    (1, fixed_intercept * convexivity_correction * fixed_year_effect),\n",
    "    color='black',\n",
    "    linewidth=2,\n",
    "    label='Average sensor'\n",
    ")\n",
    "\n",
    "ax.set_xlim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ddbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sensors = (\n",
    "    pd.Index(result.random_effects.keys())\n",
    "    .difference(locations['sensor_id'])\n",
    ")\n",
    "print(f\"Sensors in model but not in locations: {bad_sensors}\")\n",
    "\n",
    "data_clean = data[~data['sensor_id'].isin(bad_sensors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a10744",
   "metadata": {},
   "source": [
    "We see that there are a few sensors which do not have entries in our locations dataset. This means we cannot recover their locations however they still contain useful information for our regression so we will just stop considering them from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25115ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_effects = pd.merge(\n",
    "    sensor_effects, locations.drop(columns=['installation_date', 'note', 'status', 'location']), right_on='sensor_id', left_index=True, how='inner'\n",
    ")\n",
    "location_effects['percentage_change'] = round((location_effects['mean_year_effect'] - 1) * 100, 3)\n",
    "location_effects.to_parquet(config.PROCESSED_DATA_DIR / 'location_effects.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1980ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.to_parquet(config.PROCESSED_DATA_DIR / 'analysis_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
