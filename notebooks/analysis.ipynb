{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd700607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T09:48:53.907518300Z",
     "start_time": "2026-01-15T09:48:53.893520300Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cec119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T09:48:53.946336800Z",
     "start_time": "2026-01-15T09:48:53.910574100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import src.loadProcessed as loadp\n",
    "\n",
    "counts: pd.DataFrame = loadp.load_selected_count()\n",
    "locations: pd.DataFrame = loadp.load_processed_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd15606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T09:48:53.989927100Z",
     "start_time": "2026-01-15T09:48:53.981014100Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy.highlevel as phl\n",
    "import math\n",
    "\n",
    "# We want to log transform since counts have a power relation\n",
    "log_data = counts.copy()\n",
    "log_data['daily_count'] = log_data['daily_count'].apply(np.log)\n",
    "log_data['is_weekend'] = log_data['day'].isin(['Saturday', 'Sunday'])\n",
    "\n",
    "model_3 = smf.mixedlm(\n",
    "    'daily_count ~ day*year',     # Defines the response and fixed effects\n",
    "    log_data,                       \n",
    "    groups=log_data['sensor_id'],  # Defines how to cluster the data\n",
    "    re_formula='~ is_weekend*year'            # Random effect that differs across the clusters\n",
    ")\n",
    "result_3 = model_3.fit(reml=False)\n",
    "\n",
    "print(result_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d347ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Fixed Effects\n",
    "log_fixed_year = result_3.params['year[T.2025]']  # beta_1\n",
    "log_fixed_intercept = result_3.params['Intercept']  # beta_0\n",
    "\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Saturday', 'Sunday']\n",
    "log_fixed_day_effects = {d: result_3.params.get(f'day[T.{d}]', 0) for d in days}\n",
    "\n",
    "# Extract Random Effects\n",
    "log_sensor_effects = pd.DataFrame.from_dict(\n",
    "    result_3.random_effects,\n",
    "    orient='index'\n",
    ").rename(\n",
    "    columns={\n",
    "        'Group': 'b0_intercept',\n",
    "        'year[T.2025]': 'b1_year',\n",
    "        'is_weekend[T.True]': 'b2_weekend',\n",
    "        'is_weekend[T.True]:year[T.2025]': 'b3_interaction'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate the Year Effect per Day\n",
    "# Year Effect = (Fixed Year + Fixed Interaction) + (Random Year + (Random Interaction if Weekend))\n",
    "\n",
    "# Friday is the reference category for Fixed Effects (Interaction = 0)\n",
    "# It is also a Weekday (Random Interaction = 0)\n",
    "log_sensor_effects['friday_year_effect'] = log_fixed_year + log_sensor_effects['b1_year']\n",
    "\n",
    "for day in days:\n",
    "    fixed_day_interaction = f'day[T.{day}]:year[T.2025]'\n",
    "    \n",
    "    if fixed_day_interaction in result_3.params:\n",
    "        is_weekend = day in ['Saturday', 'Sunday']\n",
    "        \n",
    "        # Combine Fixed Parts: beta_1 + beta_{d x Year}\n",
    "        fixed_part = log_fixed_year + result_3.params[fixed_day_interaction]\n",
    "        \n",
    "        # Combine Random Parts: \n",
    "        # Weekdays only get b1_year. \n",
    "        # Weekends get b1_year + b3_interaction.\n",
    "        if is_weekend:\n",
    "            random_part = log_sensor_effects['b1_year'] + log_sensor_effects['b3_interaction']\n",
    "        else:\n",
    "            random_part = log_sensor_effects['b1_year']\n",
    "            \n",
    "        log_sensor_effects[f'{day.lower()}_year_effect'] = fixed_part + random_part\n",
    "\n",
    "# Calculate 2019 Intercept\n",
    "# We now use beta_d and b2_weekend to get the log-count for every day of the week in 2019\n",
    "\n",
    "# Friday 2019 has no interaction so just add the fixed intercept and the random intercept\n",
    "log_sensor_effects['friday_2019'] = log_fixed_intercept + log_sensor_effects['b0_intercept']\n",
    "\n",
    "for day in days:\n",
    "    is_weekend = day in ['Saturday', 'Sunday']\n",
    "    # Formula: Intercept + beta_d + b0_i + (b2_i if weekend)\n",
    "    baseline = log_fixed_intercept + log_fixed_day_effects[day] + log_sensor_effects['b0_intercept']\n",
    "    if is_weekend:\n",
    "        baseline += log_sensor_effects['b2_weekend']\n",
    "    \n",
    "    log_sensor_effects[f'{day.lower()}_2019'] = baseline\n",
    "\n",
    "# Average all 7 days to get the sensor-specific 2019 geometric mean log counts\n",
    "log_sensor_effects['geometric_mean_pedestrians_2019'] = log_sensor_effects[[\n",
    "    'monday_2019', 'tuesday_2019', 'wednesday_2019', 'thursday_2019', \n",
    "    'friday_2019', 'saturday_2019', 'sunday_2019'\n",
    "]].mean(axis=1)\n",
    "\n",
    "# Calculate Average Year Effect\n",
    "log_sensor_effects['mean_year_effect'] = log_sensor_effects[[\n",
    "    'monday_year_effect', 'tuesday_year_effect', 'wednesday_year_effect',\n",
    "    'thursday_year_effect', 'friday_year_effect', 'saturday_year_effect', 'sunday_year_effect'\n",
    "]].mean(axis=1)\n",
    "\n",
    "log_sensor_effects = log_sensor_effects.drop(columns=['b0_intercept'])\n",
    "convexivity_correction = np.exp(result_3.scale / 2)\n",
    "\n",
    "sensor_effects = log_sensor_effects.apply(np.exp)\n",
    "sensor_effects['arithmetic_mean_pedestrians_2019'] = (\n",
    "    sensor_effects['geometric_mean_pedestrians_2019'] * convexivity_correction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fixed_intercept = np.exp(log_fixed_intercept)\n",
    "fixed_year_effect = np.exp(log_fixed_year)\n",
    " \n",
    "for index, series in sensor_effects.sample(20).iterrows(): \n",
    "    ax.axline((0, series['arithmetic_mean_pedestrians_2019']), (1, series['arithmetic_mean_pedestrians_2019']*series['mean_year_effect']))\n",
    "\n",
    "ax.axline(\n",
    "    (0, fixed_intercept * convexivity_correction),\n",
    "    (1, fixed_intercept * convexivity_correction * fixed_year_effect),\n",
    "    color='black',\n",
    "    linewidth=2,\n",
    "    label='Average sensor'\n",
    ")\n",
    "\n",
    "ax.set_xlim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ddbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sensors = (\n",
    "    pd.Index(result_3.random_effects.keys())\n",
    "    .difference(locations['sensor_id'])\n",
    ")\n",
    "print(f\"Sensors in model but not in locations: {bad_sensors}\")\n",
    "\n",
    "data_clean = counts[~counts['sensor_id'].isin(bad_sensors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a10744",
   "metadata": {},
   "source": [
    "We see that there are a few sensors which do not have entries in our locations dataset. This means we cannot recover their locations however they still contain useful information for our regression so we will just stop considering them from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25115ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_effects = pd.merge(\n",
    "    sensor_effects, locations.drop(columns=['installation_date', 'note', 'status', 'location']), right_on='sensor_id', left_index=True, how='inner'\n",
    ")\n",
    "location_effects['percentage_change'] = round((location_effects['mean_year_effect'] - 1) * 100, 3)\n",
    "location_effects.to_parquet(config.PROCESSED_DATA_DIR / 'location_effects.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1980ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.to_parquet(config.PROCESSED_DATA_DIR / 'analysis_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
